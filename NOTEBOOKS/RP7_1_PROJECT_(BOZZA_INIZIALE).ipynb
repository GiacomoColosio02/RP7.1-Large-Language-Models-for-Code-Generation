{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# fRiend At codinG: LLMs combined with RAG for code generation\n",
        "\n",
        "# **Obiettivo:**  \n",
        "Creare un sistema modulare in grado di generare codice in diversi linguaggi (Python, Java, JavaScript) utilizzando modelli LLM combinati con tecniche di Retrieval-Augmented Generation (RAG) e prompting avanzato (few-shot e guided code generation).  \n",
        "Il sistema include inoltre una componente di valutazione basata su metriche standard (Pass@k, BLEU, CodeBLEU, METEOR, ROUGE) e un approccio LLM-based ispirato a **CodeJudge** per valutare la correttezza semantica del codice generato.\n",
        "\n",
        "# **Architettura del sistema:**  \n",
        " 1. **Code Generation Using LLM and RAG**  \n",
        "    - **A)** Motivazioni: Limitazioni degli LLM (dati obsoleti, allucinazioni, limiti contestuali)  \n",
        "   - **B1)** Retrieval basato su Embedding: Recupero di esempi rilevanti da una knowledge base (utilizzando FAISS)  \n",
        "    - **B2)** Prompting avanzato e Few-Shot Learning: Inserimento di esempi few-shot e generazione guidata (in stile AceCoder)\n",
        "\n",
        "# 2. **Code Evaluation**  \n",
        "   - **a)** Valutazione funzionale con metriche standard (Pass@k, BLEU, CodeBLEU, METEOR, ROUGE)  \n",
        "   - **b)** Valutazione semantica con CodeJudge: Un approccio LLM-based per giudicare il codice in maniera semantica\n",
        "\n",
        " Le librerie principali utilizzate includono **LangChain** per orchestrare il flusso di prompting e **FAISS** per il retrieval semantico.  "
      ],
      "metadata": {
        "id": "-8ouuMZpq7q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ## 1. Setup e Installazione\n",
        "# Installa le librerie necessarie\n",
        "!pip install langchain faiss-cpu openai sacrebleu nltk\n",
        "!pip install langchain_community\n",
        "!pip install tiktoken\n",
        "\n",
        "# Importa le librerie richieste\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from langchain.llms import OpenAI, HuggingFacePipeline\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Configurazione API key per OpenAI\n",
        "#os.environ['OPENAI_MODEL_NAME']='gpt-3.5-turbo-0125'\n",
        "#os.environ['OPENAI_MODEL_NAME']='gpt-4o-2024-08-06'\n",
        "os.environ['OPENAI_API_KEY']='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'\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "043bfbK_rGYQ",
        "outputId": "095bd4d6-3f7e-4909-9971-2550013e4aa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.41)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.41)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.20 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.20)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.8.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.11)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain_community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain_community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain_community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2. Recupero tramite Embedding (RAG)\n",
        "\n",
        " In questa sezione costruiamo un semplice knowledge base con alcuni snippet di codice e utilizziamo FAISS per indicizzare i documenti mediante embedding.\n",
        "\n",
        " L'obiettivo è: dato un prompt in linguaggio naturale, recuperare i *k* snippet più simili e utilizzarli come contesto nel prompt finale per la generazione del codice.\n",
        "\n",
        " **Nota:** In un'applicazione reale, la knowledge base dovrebbe essere molto più ampia e potrebbe essere costruita aggregando dati da fonti esterne (es. GitHub, StackOverflow, etc.). NEL NOSTRO PROGETTO SERVE QUINDI CAPIRE CHE KNOWLEDGE BASE USARE E COME SCEGLIERLA\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I1pNlbtjrx2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Esempio di knowledge base: lista di dizionari con snippet di codice -> SERVE TROVARE UN KNOWLEDGE BASE PIU GRANDE DA USARE MA QUESTO è SOLO PER PROVA\n",
        "knowledge_base = [\n",
        "    {\n",
        "        \"id\": \"ex1\",\n",
        "        \"language\": \"Python\",\n",
        "        \"code\": \"def sort_list(lst):\\n    return sorted(lst)\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"ex2\",\n",
        "        \"language\": \"JavaScript\",\n",
        "        \"code\": \"function sortArray(arr) {\\n  return arr.sort((a, b) => a - b);\\n}\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"ex3\",\n",
        "        \"language\": \"Java\",\n",
        "        \"code\": \"import java.util.*;\\npublic class Sorter {\\n  public static List<Integer> sortList(List<Integer> list) {\\n    Collections.sort(list);\\n    return list;\\n  }\\n}\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Funzione per ottenere l'embedding (utilizziamo il modello OpenAI embeddings)\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "def get_embedding(text):\n",
        "    return embedding_model.embed_query(text)\n",
        "\n",
        "# Costruisci una matrice degli embedding per ogni snippet della knowledge base\n",
        "example_embeddings = np.array([get_embedding(example[\"code\"]) for example in knowledge_base]).astype(\"float32\")\n",
        "\n",
        "# Costruisci l'indice FAISS\n",
        "dimension = example_embeddings.shape[1]\n",
        "index = FAISS.from_texts([ex[\"code\"] for ex in knowledge_base], embedding_model, metadatas=knowledge_base)\n",
        "print(f\"Indice FAISS costruito con {index.index.ntotal} esempi.\")\n",
        "\n",
        "\n",
        "# Funzione per recuperare gli snippet più simili dato un prompt\n",
        "def retrieve_examples(prompt, k=2):\n",
        "    results = index.similarity_search(prompt, k=k)\n",
        "    return results\n",
        "\n",
        "\n",
        "# Esempio di recupero\n",
        "test_prompt = \"Scrivi una funzione Python per ordinare una lista di numeri.\"\n",
        "retrieved_examples = retrieve_examples(test_prompt, k=2)\n",
        "print(\"Esempi recuperati:\")\n",
        "for doc in retrieved_examples:\n",
        "    print(f\"ID: {doc.metadata['id']} | Language: {doc.metadata['language']}\")\n",
        "    print(doc.page_content)\n",
        "    print(\"---------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt-MKSzCr1yB",
        "outputId": "6a57ce37-e2e2-4313-9903-28fc3bd723b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indice FAISS costruito con 3 esempi.\n",
            "Esempi recuperati:\n",
            "ID: ex3 | Language: Java\n",
            "import java.util.*;\n",
            "public class Sorter {\n",
            "  public static List<Integer> sortList(List<Integer> list) {\n",
            "    Collections.sort(list);\n",
            "    return list;\n",
            "  }\n",
            "}\n",
            "---------------------------\n",
            "ID: ex1 | Language: Python\n",
            "def sort_list(lst):\n",
            "    return sorted(lst)\n",
            "---------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Generazione di Codice con Prompting Avanzato\n",
        " In questa sezione costruiamo il prompt finale per la generazione del codice.\n",
        "\n",
        " Il prompt integra:\n",
        " 1. La descrizione del problema (input dell’utente).\n",
        " 2. Un output preliminare per guidare la generazione (es. analisi dei requisiti e test case – in stile AceCoder).\n",
        " 3. Gli esempi recuperati (few-shot learning) dalla knowledge base.\n",
        "\n",
        "Utilizzeremo **LangChain** per strutturare il prompt e per invocare l'LLM generativo.\n"
      ],
      "metadata": {
        "id": "gdmaVWlUtkpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura l'LLM generativo (qui usiamo OpenAI GPT-4; nel progetto completo useremo differenti llms come CodeLlama o StarCoder)\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.2) # or model_name=\"gpt-4\"\n",
        "\n",
        "# Definisci un template di prompt che integra il task, un'analisi preliminare e gli esempi recuperati. -> QUI VOGLIO CAPIRE COME è POSSIBILE DA UNA RICHIESTA IN LINGUAGGIO NATURALE OTTENERE ANALISI, ESEMPI (FEW SHOT LEARNING) E ISTRUZIONI IN MANIERA AUTOMATICA {crew ai library=}\n",
        "prompt_template = \"\"\"\n",
        "## Problema:\n",
        "{task_description}\n",
        "\n",
        "## Analisi preliminare:\n",
        "Per comprendere meglio il compito, fornisci un'analisi dei requisiti e, se possibile, genera alcuni casi di test o uno pseudocodice che delinei cosa il codice deve fare.\n",
        "\n",
        "## Esempi di riferimento:\n",
        "{examples}\n",
        "\n",
        "## Istruzioni:\n",
        "Ora, scrivi il codice completo per risolvere il problema.\n",
        "\"\"\"\n",
        "\n",
        "# Prepara il testo degli esempi recuperati\n",
        "examples_text = \"\\n\\n\".join([f\"### Esempio ({doc.metadata['language']}):\\n{doc.page_content}\" for doc in retrieved_examples])\n",
        "\n",
        "# Costruisci il prompt finale\n",
        "final_prompt = prompt_template.format(task_description=test_prompt, examples=examples_text)\n",
        "print(\"Prompt finale per la generazione di codice:\")\n",
        "print(final_prompt)\n",
        "\n",
        "# Crea la catena LLM tramite LangChain\n",
        "chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=PromptTemplate(\n",
        "        template=prompt_template,\n",
        "        input_variables=[\"task_description\", \"examples\"]\n",
        "    )\n",
        ")\n",
        "\n",
        "# Genera il codice\n",
        "generated_code = chain.run(task_description=test_prompt, examples=examples_text)\n",
        "print(\"Codice generato:\")\n",
        "print(generated_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8TfXmNgtr7i",
        "outputId": "6be29bf7-cd08-4e7b-bc0a-a95e1141a233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-e00a1a2e4af1>:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.2) # or model_name=\"gpt-4\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt finale per la generazione di codice:\n",
            "\n",
            "## Problema:\n",
            "Scrivi una funzione Python per ordinare una lista di numeri.\n",
            "\n",
            "## Analisi preliminare:\n",
            "Per comprendere meglio il compito, fornisci un'analisi dei requisiti e, se possibile, genera alcuni casi di test o uno pseudocodice che delinei cosa il codice deve fare.\n",
            "\n",
            "## Esempi di riferimento:\n",
            "### Esempio (Java):\n",
            "import java.util.*;\n",
            "public class Sorter {\n",
            "  public static List<Integer> sortList(List<Integer> list) {\n",
            "    Collections.sort(list);\n",
            "    return list;\n",
            "  }\n",
            "}\n",
            "\n",
            "### Esempio (Python):\n",
            "def sort_list(lst):\n",
            "    return sorted(lst)\n",
            "\n",
            "## Istruzioni:\n",
            "Ora, scrivi il codice completo per risolvere il problema.\n",
            "\n",
            "Codice generato:\n",
            "```python\n",
            "def sort_list(lst):\n",
            "    return sorted(lst)\n",
            "\n",
            "# Esempio di utilizzo\n",
            "numbers = [4, 2, 7, 1, 9, 5]\n",
            "sorted_numbers = sort_list(numbers)\n",
            "print(sorted_numbers)\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 4. Valutazione del Codice Generato\n",
        "\n",
        " In questa sezione implementiamo due modalità di valutazione:\n",
        "\n",
        " 1. **Valutazione Funzionale con Metriche Standard**:  \n",
        "    - Esecuzione del codice in una sandbox per verificare il corretto funzionamento (es. calcolo del Pass@k).\n",
        "    - Calcolo di metriche come BLEU, CodeBLEU, METEOR e ROUGE.\n",
        "\n",
        " 2. **Valutazione Semantica con CodeJudge (LLM-based)**:  \n",
        "    - Utilizzo di un LLM (ad es. GPT-4) per analizzare il codice generato in relazione alla descrizione del problema e fornire un giudizio dettagliato.\n",
        "\n",
        "Per semplicità, in questo notebook implementiamo versioni semplificate di questi processi.\n"
      ],
      "metadata": {
        "id": "Zt3SxcsZwFjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.1 Esecuzione simulata dei test unitari per calcolare Pass@k\n",
        "def run_unit_tests(code_snippet, language=\"Python\"):\n",
        "    \"\"\"\n",
        "    Funzione simulata per eseguire test unitari.\n",
        "    In un'applicazione reale, questa funzione eseguirà il codice in una sandbox e verificherà i test case.\n",
        "    Per questo esempio, se il codice contiene 'sorted' lo consideriamo corretto.\n",
        "    \"\"\"\n",
        "    if \"sorted\" in code_snippet:\n",
        "        return True, \"Test passed.\"\n",
        "    return False, \"Test failed: codice non contiene la logica attesa.\"\n",
        "\n",
        "test_result, test_log = run_unit_tests(generated_code)\n",
        "print(\"Risultato dei test automatici:\")\n",
        "print(\"Pass:\", test_result)\n",
        "print(\"Log:\", test_log)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1PEXfpUwMvG",
        "outputId": "94a27a82-4aae-431f-8495-ca34a51209b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Risultato dei test automatici:\n",
            "Pass: True\n",
            "Log: Test passed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.2 Valutazione semantica ispirata a CodeJudge\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "\n",
        "def codejudge_evaluation(code_snippet, task_description):\n",
        "    \"\"\"\n",
        "    Funzione per valutare il codice usando un LLM come giudice (in stile CodeJudge).\n",
        "    Costruisce un prompt per far analizzare il codice al modello e ne restituisce il giudizio.\n",
        "    \"\"\"\n",
        "    evaluation_prompt = f\"\"\"\n",
        "    Sei un esperto revisore di codice. Analizza attentamente il seguente problema e la soluzione proposta.\n",
        "\n",
        "    ## Problema:\n",
        "    {task_description}\n",
        "\n",
        "    ## Codice proposto:\n",
        "    {code_snippet}\n",
        "\n",
        "    Spiega passo per passo se il codice risolve il problema in maniera corretta. Indica eventuali errori logici o di implementazione.\n",
        "    Alla fine, rispondi con 'Verdetto: CORRETTO' se il codice è funzionale, oppure 'Verdetto: ERRATO' se ci sono errori.\n",
        "    \"\"\"\n",
        "    # Create a HumanMessage object with the prompt\n",
        "    messages = [HumanMessage(content=evaluation_prompt)]\n",
        "    # Pass messages to the LLM\n",
        "    evaluation = llm(messages)\n",
        "    return evaluation.content  # Access the content of the AIMessage\n",
        "\n",
        "evaluation_result = codejudge_evaluation(generated_code, test_prompt)\n",
        "print(\"Valutazione semantica del codice (ispirata a CodeJudge):\")\n",
        "print(evaluation_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4xOfphdxEAo",
        "outputId": "8918b6fe-089d-465b-c6d4-a79498821217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valutazione semantica del codice (ispirata a CodeJudge):\n",
            "Il codice proposto definisce una funzione `sort_list(lst)` che prende in input una lista di numeri `lst` e restituisce la lista ordinata utilizzando la funzione `sorted()` di Python. Successivamente viene creato un esempio di utilizzo della funzione con una lista di numeri non ordinata, viene chiamata la funzione `sort_list()` e il risultato viene stampato a schermo.\n",
            "\n",
            "Il codice risolve correttamente il problema di ordinare una lista di numeri in maniera crescente. Non ci sono errori logici o di implementazione nel codice proposto.\n",
            "\n",
            "Verdetto: CORRETTO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 5. Conclusioni e Prossimi Passi\n",
        "\n",
        " In questo notebook abbiamo implementato un sistema di **generazione di codice** basato su LLM e RAG, che integra:\n",
        "\n",
        " - **Retrieval basato su embedding**: per arricchire il prompt con esempi rilevanti.\n",
        " - **Prompting avanzato (few-shot e guided code generation)**: per generare codice in modo più accurato.\n",
        " - **Valutazione del codice**: tramite test automatici (Pass@k) e una componente LLM-based ispirata a CodeJudge per una valutazione semantica.\n",
        "\n",
        "**Prossimi passi:**  \n",
        " - Integrare una knowledge base più ampia e aggiornata per il retrieval.  \n",
        " - Estendere il modulo di valutazione per includere altre metriche (CodeBLEU, METEOR, ROUGE).  \n",
        " - Confrontare le performance di diversi LLM (es. CodeLlama vs. GPT-4 vs. StarCoder) utilizzando il framework modulare.  \n",
        " - Ottimizzare il processo di prompting e testare approcci iterativi per il refining del codice.\n",
        "\n",
        " Questo prototipo fornisce una base solida per lo sviluppo di un sistema di code generation e valutazione robusto e flessibile.\n"
      ],
      "metadata": {
        "id": "WC2RHr_Uyz_z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hlD-ZnLBy7Ch"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}